[
  {
    "objectID": "course/practical-6-odes.html",
    "href": "course/practical-6-odes.html",
    "title": "ODEs with JAX",
    "section": "",
    "text": "A big benefit of using JAX to write our statistical models is that we don’t have to use specialised HMC optimised ODE software. As long as an ODE solving library is generally JAX-compatible, we can use it in our Bayesian statistical models.\nIn practice there are two main choices: probdiffeq and diffrax. Here we’ll focus on diffrax, as we (Teddy, Nick and Sergi) have more experience with it.\nWe’ll use diffrax to solve the initial value problem introduced in the last session, then embed this solution inside a statistical model.",
    "crumbs": [
      "Practical",
      "ODEs with JAX"
    ]
  },
  {
    "objectID": "course/practical-6-odes.html#imports",
    "href": "course/practical-6-odes.html#imports",
    "title": "ODEs with JAX",
    "section": "imports",
    "text": "imports\n\nfrom functools import partial\n\nimport operator\nimport arviz as az\nimport diffrax\nimport numpy as np\nimport jax\n\nfrom jax import numpy as jnp\nfrom jax import scipy as jsp\nfrom matplotlib import pyplot as plt\n\n\nSpecify true parameters\nThis code specifies the dimensions of our problem.\n\nN_strain = 4\nN_tube = 16\nN_timepoint = 50\nduration = 30\nstrains = [i + 1 for i in range(N_strain)]\ntubes = [i + 1 for i in range(N_tube)]\nspecies = [\"biomass\", \"substrate\"]\nmeasurement_times = np.array([4.0, 7.0, 12.0, 15.0, 17.0])\ntimepoints = jnp.linspace(0.01, duration, N_timepoint)\n\nTo generate random numbers with JAX we need to explicitly create some random key objects.\n\nSEED = 12345\nkey = jax.random.key(seed=SEED)\nrng_key, key = jax.random.split(key)\nrng_key_a, rng_key_b, rng_key_c, rng_key_d = jax.random.split(rng_key, 4)\n\nThis code defines some true values for the parameters - we will use these to generate fake data. Note that we avoid putting any constrained variables in the parameters using some log transformations.\n\na_mu_max = -1.7\nlog_t_mu_max = jnp.log(0.2)\na_ks = -1.3\na_mu_max = -1.7\na_gamma = -0.6\ntau_mu_max = 0.2\ntau_ks = 0.3\ntau_gamma = 0.13\ntarget_conc_init = jnp.array([-2.1, 0.2])\ntarget_conc_init_scale = jnp.array([0.1, 0.05])\n\ntrue_params = {\n    \"a_mu_max\": a_mu_max,\n    \"a_ks\": a_ks,\n    \"a_gamma\": a_gamma,\n    \"log_tau_mu_max\": jnp.log(tau_mu_max),\n    \"log_tau_ks\": jnp.log(tau_ks),\n    \"log_tau_gamma\": jnp.log(tau_gamma),\n    \"log_conc_init\": target_conc_init\n    + target_conc_init_scale\n    * jax.random.normal(\n        key=rng_key_a,\n        shape=(N_strain, 2),\n    ),\n    \"log_sigma\": jnp.log(jnp.array([0.08, 0.1])),\n    \"log_mu_max\": a_mu_max\n    + tau_mu_max * jax.random.normal(rng_key_b, shape=(N_strain,)),\n    \"log_ks\": a_ks + tau_ks * jax.random.normal(rng_key_c, shape=(N_strain,)),\n    \"log_gamma\": a_gamma\n    + tau_gamma\n    * jax.random.normal(\n        rng_key_d,\n        shape=(N_strain,),\n    ),\n}\n\n\ndef get_strain_params(strain_ix, params):\n    def slice(leaf):\n        return (\n            leaf[strain_ix]\n            if (hasattr(leaf, \"shape\") and leaf.ndim &gt; 0 and leaf.shape[0] == N_strain)\n            else leaf\n        )\n\n    return jax.tree.map(slice, params)\n\ntrue_params_strain_2 = get_strain_params(2, true_params)\ntrue_params_strain_2\n\n{'a_gamma': -0.6,\n 'a_ks': -1.3,\n 'a_mu_max': -1.7,\n 'log_conc_init': Array([-2.043062,  0.148519], dtype=float32),\n 'log_gamma': Array(-0.5753846, dtype=float32),\n 'log_ks': Array(-1.4795702, dtype=float32),\n 'log_mu_max': Array(-1.9427458, dtype=float32),\n 'log_sigma': Array([-2.5257287, -2.3025851], dtype=float32),\n 'log_tau_gamma': Array(-2.040221, dtype=float32, weak_type=True),\n 'log_tau_ks': Array(-1.2039728, dtype=float32, weak_type=True),\n 'log_tau_mu_max': Array(-1.609438, dtype=float32, weak_type=True)}\n\n\n\n\nDefining the dynamics\nTo implement our model using diffrax, we need to write down the dynamics as a Python function with a special signature t, y, args, where t is a float representing the time, y is a jax array of state variables and args is an arbitrary auxiliary PyTree, in this case a dictionary of parameters pertaining to a strain.\n\ndef monod_kinetics(t, y, args):\n    x, s = y\n    mu_max = jnp.exp(args[\"log_mu_max\"])\n    ks = jnp.exp(args[\"log_ks\"])\n    gamma = jnp.exp(args[\"log_gamma\"])\n    mu = (mu_max * s) / (ks + s)\n    return jnp.array([mu * x, -gamma * mu * x])\n\n\n\nSolving the initial value problem\nThe next step is to wrap this function using the diffrax class ODETerm\n\nmonod_term = diffrax.ODETerm(monod_kinetics)\n\nNow we can choose a solver, stepsize controller and initial sensitivity\n\nsolver = diffrax.Kvaerno5()\nstepsize_controller = diffrax.PIDController(rtol=1e-8, atol=1e-8)\ndt0 = 0.001\n\nNow we can make a function for solving our initial value problem\n\ndef solve_monod(args, timepoints):\n    t0 = 0.0\n    tf = timepoints[-1]\n    y0 = jnp.exp(args[\"log_conc_init\"])\n    saveat = diffrax.SaveAt(ts=timepoints)\n    return diffrax.diffeqsolve(\n        monod_term,\n        solver,\n        t0=t0,\n        t1=tf,\n        dt0=dt0,\n        y0=y0,\n        saveat=saveat,\n        args=args,\n        stepsize_controller=stepsize_controller,\n    )\n\nsolution = solve_monod(args=true_params_strain_2, timepoints=timepoints)\n\n\nf, ax = plt.subplots()\nfor yi, label in zip(solution.ys.T, [\"substrate\", \"product\"]):\n    ax.plot(timepoints, yi, label=label)\nax.legend()\n\n\n\n\n\n\n\n\nNice!",
    "crumbs": [
      "Practical",
      "ODEs with JAX"
    ]
  },
  {
    "objectID": "course/practical-6-odes.html#defining-a-model",
    "href": "course/practical-6-odes.html#defining-a-model",
    "title": "ODEs with JAX",
    "section": "Defining a model",
    "text": "Defining a model\n\nJoint log density function\nThe next step is to write a joint log density function that connects parameters and data with measurables using solve_monod. We’ll do this bit by bit, starting with the prior log density:\n\ndef prior_log_density(params, prior):\n    loc, scale = prior\n    return jax.tree.map(jsp.stats.norm.logpdf, params, loc, scale)\n\nexample_prior_loc = jax.tree.map(jnp.array, true_params)\nexample_prior_scale = jax.tree.map(\n    lambda x: jnp.full_like(x, 0.1),\n    true_params,\n)\nexample_prior = (example_prior_loc, example_prior_scale)\nexample_log_prior = prior_log_density(true_params, example_prior)\nexample_log_prior\n\n{'a_gamma': Array(1.3836465, dtype=float32, weak_type=True),\n 'a_ks': Array(1.3836465, dtype=float32, weak_type=True),\n 'a_mu_max': Array(1.3836465, dtype=float32, weak_type=True),\n 'log_conc_init': Array([[1.3836465, 1.3836465],\n        [1.3836465, 1.3836465],\n        [1.3836465, 1.3836465],\n        [1.3836465, 1.3836465]], dtype=float32),\n 'log_gamma': Array([1.3836465, 1.3836465, 1.3836465, 1.3836465], dtype=float32),\n 'log_ks': Array([1.3836465, 1.3836465, 1.3836465, 1.3836465], dtype=float32),\n 'log_mu_max': Array([1.3836465, 1.3836465, 1.3836465, 1.3836465], dtype=float32),\n 'log_sigma': Array([1.3836465, 1.3836465], dtype=float32),\n 'log_tau_gamma': Array(1.3836465, dtype=float32, weak_type=True),\n 'log_tau_ks': Array(1.3836465, dtype=float32, weak_type=True),\n 'log_tau_mu_max': Array(1.3836465, dtype=float32, weak_type=True)}\n\n\nnow the likelihood:\n\ndef likelihood_log_density(obs, params, measurement_times):\n    n_strain = params[\"log_mu_max\"].shape[0]\n    strains = jnp.arange(n_strain)\n    yhat = jax.vmap(\n        lambda i: solve_monod(get_strain_params(i, params), measurement_times).ys,\n    )(strains)\n    log_yhat = jnp.log(jnp.maximum(yhat, jnp.full_like(yhat, 1e-9)))\n    sigma = jnp.exp(params[\"log_sigma\"])\n    log_obs = jnp.log(obs)\n    return jsp.stats.norm.logpdf(log_obs, log_yhat, sigma)\n\n\ndef simulate_measurements(key, params, measurement_times):\n    n_strain = params[\"log_mu_max\"].shape[0]\n    strains = jnp.arange(n_strain)\n    yhat = jax.vmap(\n        lambda i: solve_monod(get_strain_params(i, params), measurement_times).ys\n    )(strains)\n    sigma = jnp.exp(params[\"log_sigma\"])\n    noise = jax.random.normal(key, shape=yhat.shape) * sigma\n    return jnp.exp(jnp.log(yhat) + noise)\n\n\nsim_key, key = jax.random.split(key)\nexample_obs = simulate_measurements(sim_key, true_params, measurement_times)\nexample_obs\n\nArray([[[0.22783391, 0.96208405],\n        [0.2802295 , 1.1829902 ],\n        [0.6151478 , 0.96014714],\n        [0.808359  , 0.8715509 ],\n        [1.0103092 , 0.59285116]],\n\n       [[0.23718558, 0.87122196],\n        [0.2716521 , 1.252538  ],\n        [0.46342003, 0.94091225],\n        [0.6423971 , 1.1722577 ],\n        [0.78577113, 0.8686925 ]],\n\n       [[0.23523214, 1.3224756 ],\n        [0.29459015, 0.84505486],\n        [0.48906034, 1.069513  ],\n        [0.64119184, 0.58480805],\n        [0.7719773 , 0.76687366]],\n\n       [[0.19057587, 1.1378189 ],\n        [0.2525575 , 1.0086107 ],\n        [0.4153177 , 0.83254826],\n        [0.6303718 , 1.1003901 ],\n        [0.6436955 , 0.885998  ]]], dtype=float32)\n\n\n\nlikelihood_log_density(example_obs, true_params, measurement_times)\n\nArray([[[ 0.6803185 ,  0.21532977],\n        [ 1.2108381 ,  0.8320693 ],\n        [ 1.0624793 ,  1.2488012 ],\n        [ 1.6026926 ,  0.5788903 ],\n        [ 1.588413  ,  1.0270905 ]],\n\n       [[-0.29656756, -1.6563145 ],\n        [ 1.5831385 ,  0.18755579],\n        [ 1.6001872 ,  1.3399622 ],\n        [ 1.4896955 , -2.7660604 ],\n        [ 1.4342949 ,  1.0837686 ]],\n\n       [[ 0.51660633, -0.0654397 ],\n        [ 1.5944276 , -1.2969908 ],\n        [ 0.9780934 ,  0.43840444],\n        [-0.3893932 , -3.9161468 ],\n        [-1.3531868 ,  1.035675  ]],\n\n       [[ 1.6066262 ,  1.3783708 ],\n        [ 1.5671532 ,  0.90355957],\n        [ 1.5661874 , -0.6937643 ],\n        [ 0.7906398 ,  0.16633916],\n        [ 1.2486979 ,  1.3766443 ]]], dtype=float32)\n\n\nAnd finally we can write down a joint log density function\n\ndef joint_log_density(params, obs, prior, measurement_times):\n    lprior = prior_log_density(params, prior)\n    llik = likelihood_log_density(obs, params, measurement_times)\n    lprior_sum = jax.tree.reduce(operator.add, jax.tree.map(jnp.sum, lprior))\n    llik_sum = jax.tree.reduce(operator.add, jax.tree.map(jnp.sum, llik))\n    return lprior_sum + llik_sum\n\n\njoint_log_density(true_params, example_obs,  example_prior, measurement_times)\n\nArray(60.241196, dtype=float32)\n\n\n\n\nPosterior\nWhen we have concrete values for observations, prior and measurement times, we want a new function based on the joint log density, where these values are fixed. This is an ideal job for the Python standard library function partial. The resulting posterior log density function has only one argument for parameters.\n\nposterior_log_density = partial(\n    joint_log_density,\n    obs=example_obs,\n    prior=example_prior,\n    measurement_times=measurement_times\n)\nposterior_log_density(true_params)\n\nArray(60.241196, dtype=float32)",
    "crumbs": [
      "Practical",
      "ODEs with JAX"
    ]
  },
  {
    "objectID": "course/practical-6-odes.html#mcmc",
    "href": "course/practical-6-odes.html#mcmc",
    "title": "ODEs with JAX",
    "section": "MCMC",
    "text": "MCMC\nNow we can generate posterior samples using adaptive Hamiltonian Monte Carlo via the library blackjax.\n\n\n\n\n\n\nNote\n\n\n\nMulti-chain MCMC with Blackjax is a bit annoying to do manually so I made some convenience functions run_nuts and get_idata. These should probably already be installed - if not just run uv sync from the project root.\n\n\n\nfrom blackjax_utils import run_nuts, get_idata\nstates, info = run_nuts(\n    key,\n    jax.jit(posterior_log_density),\n    init_params=example_prior_loc,\n    n_chain=4,\n    n_warmup=200,\n    n_sample=200,\n    target_acceptance_rate=0.9,\n    initial_step_size=0.001,\n)\n\ncoords = {\n    \"strain\": strains,\n    \"tube\": tubes,\n    \"species\": species,\n    \"timepoint\": timepoints,\n}\ndims = {\n    \"log_conc_init\": [\"strain\", \"species\"],\n    \"log_gamma\": [\"strain\"],\n    \"log_ks\": [\"strain\"],\n    \"log_mu_max\": [\"strain\"],\n    \"log_sigma\": [\"species\"],\n}\n\nidata = get_idata(states, info, coords=coords, dims=dims)\nn_divergent = idata.sample_stats[\"is_divergent\"].sum().item()\nprint(f\"Number of divergent transitions: {n_divergent}\")\nprint(az.summary(idata))\n\nNumber of divergent transitions: 0\n                              mean     sd  hdi_3%  hdi_97%  mcse_mean  \\\na_gamma                     -0.601  0.095  -0.771   -0.425      0.002   \na_ks                        -1.303  0.113  -1.509   -1.099      0.003   \na_mu_max                    -1.698  0.100  -1.882   -1.517      0.002   \nlog_conc_init[1, biomass]   -2.073  0.060  -2.182   -1.955      0.002   \nlog_conc_init[1, substrate]  0.163  0.045   0.076    0.249      0.001   \nlog_conc_init[2, biomass]   -1.954  0.057  -2.066   -1.855      0.002   \nlog_conc_init[2, substrate]  0.179  0.045   0.094    0.260      0.001   \nlog_conc_init[3, biomass]   -1.968  0.059  -2.073   -1.859      0.002   \nlog_conc_init[3, substrate]  0.094  0.045   0.013    0.173      0.002   \nlog_conc_init[4, biomass]   -2.064  0.061  -2.183   -1.948      0.002   \nlog_conc_init[4, substrate]  0.151  0.043   0.072    0.236      0.001   \nlog_gamma[1]                -0.553  0.087  -0.712   -0.387      0.003   \nlog_gamma[2]                -0.606  0.100  -0.792   -0.425      0.004   \nlog_gamma[3]                -0.549  0.104  -0.749   -0.361      0.004   \nlog_gamma[4]                -0.612  0.101  -0.791   -0.406      0.003   \nlog_ks[1]                   -1.214  0.093  -1.392   -1.040      0.003   \nlog_ks[2]                   -1.156  0.106  -1.359   -0.964      0.003   \nlog_ks[3]                   -1.455  0.101  -1.642   -1.270      0.004   \nlog_ks[4]                   -1.057  0.096  -1.231   -0.877      0.002   \nlog_mu_max[1]               -1.822  0.047  -1.910   -1.736      0.002   \nlog_mu_max[2]               -2.050  0.054  -2.141   -1.942      0.002   \nlog_mu_max[3]               -2.049  0.051  -2.149   -1.965      0.002   \nlog_mu_max[4]               -2.026  0.056  -2.132   -1.924      0.002   \nlog_sigma[biomass]          -2.558  0.094  -2.716   -2.372      0.003   \nlog_sigma[substrate]        -2.113  0.080  -2.261   -1.967      0.002   \nlog_tau_gamma               -2.049  0.102  -2.249   -1.861      0.003   \nlog_tau_ks                  -1.204  0.099  -1.401   -1.044      0.002   \nlog_tau_mu_max              -1.606  0.096  -1.798   -1.434      0.003   \n\n                             mcse_sd  ess_bulk  ess_tail  r_hat  \na_gamma                        0.003    1653.0     656.0   1.00  \na_ks                           0.005    1819.0     561.0   1.00  \na_mu_max                       0.004    1993.0     714.0   1.00  \nlog_conc_init[1, biomass]      0.002     720.0     592.0   1.00  \nlog_conc_init[1, substrate]    0.002    1155.0     684.0   1.00  \nlog_conc_init[2, biomass]      0.002     656.0     549.0   1.01  \nlog_conc_init[2, substrate]    0.002    1074.0     701.0   1.01  \nlog_conc_init[3, biomass]      0.002     789.0     530.0   1.00  \nlog_conc_init[3, substrate]    0.001     811.0     530.0   1.00  \nlog_conc_init[4, biomass]      0.002     883.0     481.0   1.00  \nlog_conc_init[4, substrate]    0.002    1216.0     678.0   1.02  \nlog_gamma[1]                   0.003     807.0     580.0   1.00  \nlog_gamma[2]                   0.004     784.0     526.0   1.00  \nlog_gamma[3]                   0.003     789.0     590.0   1.01  \nlog_gamma[4]                   0.004    1326.0     559.0   1.01  \nlog_ks[1]                      0.004     883.0     520.0   1.01  \nlog_ks[2]                      0.004     963.0     515.0   1.00  \nlog_ks[3]                      0.004     749.0     572.0   1.01  \nlog_ks[4]                      0.004    1763.0     629.0   1.00  \nlog_mu_max[1]                  0.001     630.0     562.0   1.00  \nlog_mu_max[2]                  0.002     564.0     644.0   1.00  \nlog_mu_max[3]                  0.002     650.0     606.0   1.00  \nlog_mu_max[4]                  0.002     795.0     586.0   1.00  \nlog_sigma[biomass]             0.003    1028.0     528.0   1.01  \nlog_sigma[substrate]           0.003    1752.0     582.0   1.00  \nlog_tau_gamma                  0.003     930.0     654.0   1.00  \nlog_tau_ks                     0.004    1633.0     691.0   1.00  \nlog_tau_mu_max                 0.004    1031.0     632.0   1.00  \n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow good was our model?\nTo answer this question, try:\n\nfor each parameter, compare the true value with the model’s marginal posterior distribution.\nplot the timecourses for a sample of parameters and compare with the real timecourse",
    "crumbs": [
      "Practical",
      "ODEs with JAX"
    ]
  }
]