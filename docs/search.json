[
  {
    "objectID": "course_materials/day-2-am-regression.html",
    "href": "course_materials/day-2-am-regression.html",
    "title": "Day 2 am: Regression and formula-based models",
    "section": "",
    "text": "Recall from the previous session that one of the advantages of Bayesian statistical inference—aka using a sample to answer questions about a population in the form of probability statements—is that probability functions decompose into the following convenient form:\n\\[\np(y, \\theta) \\propto p(\\theta)p(y\\mid\\theta)\n\\]\nIn particular, we mentioned that the form \\(p(y\\mid\\theta)\\) is convenient for representing data generating processes.\nRegression is the main way to flesh out this idea: it provides specific ways to say, for data \\(y\\) and parameters \\(\\theta\\), what is the likelihood \\(p(y\\mid\\theta)\\).\nThe key idea of regression is to separate out some components of \\(y\\) called “covariates”, or “independent” variables, and typically denoted \\(x\\). Here we will use the term \\(y_{\\text{dep}}\\) to refer to the other members of \\(y\\), typically called “variates” or “dependent variables” and used to represent things that are measured in an experiment.\n\nThe rest of this course, an most statistics notation, typically omits the subscript \\(_{\\text{dep}}\\) in \\(y_{\\text{dep}}\\) and \\(\\hat{y}_{\\text{dep}}\\), as there is usually no need to refer to the full data \\(y=\\{x, y_{dep}\\}\\).\n\nWith this split made, the next step in regression modelling is to define a way to turn the covariates into a summary statistic, then connect this statistic probabilistically with \\(y_{\\text{dep}}\\). In mathematical notation, this means that a regression model has this form:\n\\[\np(y\\mid\\theta) = p(y_{\\text{dep}}\\mid T(x, \\theta), \\theta)\n\\]\nwhere \\(T\\) is a deterministic function that maps any \\(x\\) and \\(\\theta\\) to a summary statistic.\nA popular approach, which we will concentrate on in this course, is for the summary statistic \\(T(x, \\theta)=\\hat{y}_{\\text{dep}}(x, \\theta)\\) to be an estimate of the most likely, or “expected”, value of \\(y_{dep}\\). Alternatively, in quantile regression the summary statistic estimates an extreme value of \\(y_{dep}\\).\nFormulating \\(p(y\\mid\\theta)\\) up in this way allows a regression modeller to separately create a deterministic model of the underlying process and a probabilistic model of the measurement process. This separation is very convenient!\nBeing able to choose any deterministic function \\(T\\) to represent the relationship between \\(x\\), \\(\\theta\\) and \\(y_{dep}\\) allows the modeller a lot of freedom to represent domain knowledge. For example, \\(T\\) might encode a kinetic model connecting experimental conditions with things we can measure in a bioreactor.\nOn the other hand, writing down a function \\(p(y_{\\text{dep}}\\mid T(x, \\theta), \\theta)\\) is often easier than directly specifying a likelihood function \\(p(y\\mid\\theta)\\). The former, regression-based formulation is natural for representing how noisy measurements work. For example, regression models often represent measurements using the normal distribution:\n\\[\n\\begin{align*}\n\\theta &= \\theta_1, ..., \\theta_k, \\sigma \\\\\nT(x, \\theta) &= T(x, \\theta_1, ..., \\theta_k) = \\hat{y}_{\\text{dep}}\\\\\np(y_{\\text{dep}}\\mid T(x, \\theta), \\theta) &= N(y_{\\text{dep}}\\mid \\hat{y}_{\\text{dep}}, \\sigma)\n\\end{align*}\n\\]\nIn this equation \\(N\\) indicates the normal probability density function:\n\\[\nN(y_{\\text{dep}}\\mid\\hat{y}_{\\text{dep}},\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp{-\\frac{(y_{\\text{dep}}-\\hat{y}_{\\text{dep}})^2}{2\\sigma^2}}\n\\]\nTo get an intuition for why this makes sense as a way to represent a measurement, consider the following plot of this function:\n\nNote that, as we usually expect for a measurement, the density is highest when the measured and expected values are the same, and smoothly and symmetrically decreases with this distance. The accuracy of the measurement can be captured by the parameter \\(\\sigma\\), as shown by comparing the blue and orange lines.\n\n\nHere are some rules of thumb for representing measurements using probability distributions.\nThe most important thing is to consider are natural constraints: where does the measurement have to live?\n\n\nIf both measureable and measurement can in principle live on any the real line, the Normal regression model presented above is usually a good starting point. Many standard statistical methods explicitly or implicitly assume such a model.\nIf your unconstrained measurements come in batches, consider whether they are likely to be correlated, so that the value of one batch component could be informative about the value of another. If so, you may want to use a multivariate normal distribution to model your measurements.\nIf, as happens quite often, your unconstrained measurements potentially include outliers, they may be better described using a measurement distribution with heavier tails than the normal distribution, such as the student-T distribution.\nIf your unconstrained measurements are skewed, so that errors in one direction are more likely than the other, consider modelling them with a skew-normal distribution.\n\n\n\nWe often want to measure things that cannot possibly be negative, like concentrations or temperatures. This kind of measurement is often not well described by the normal distribution.\nFirst, note that the normal distribution has support across the whole real number line, half of which is inaccessible to a non-negative measurement. Modelling non-negative measurements using the normal distribution therefore necessarily involves allocating probability mass to something structurally impossible. How big of a problem this is in practice depends on the amount of probability mass misallocated: this in turn depends on the distance in measurement standard deviations from \\(\\hat{y}_{\\text{dep}}\\) to zero. As a general rule of thumb, if this distance is less than 3 standard deviations for any measurement, there is a potential problem.\nSecond, note that the normal probability density function is symmetrical: the density decreases at the same rate both up and down from \\(y_{\\text{dep}}-\\hat{y}_{\\text{dep}}=0\\). This behaviour is desirable when an error gets less likely proportionally to its absolute size. However non-negative measurement errors are often naturally expressed relatively, not absolutely. If you usually talk about your errors in terms like “+/- 10%” or similar, an unconstrained probability distribution is probably a bad fit.\nFor these reasons, when modelling non-negative measurements, it is often a good idea to use a probability distribution whose support lies only on the non-negative real line. This can often easily be done by log-transforming the measurements and then using an unconstrained measurement distribution centred at the logarithm of \\(\\hat{y}_{\\text{dep}}\\).\n\n\n\nTry transforming the measurements to unconstrained space using the inverse hyperbolic tangent function.\n\n\n\nUse the poisson distribution.\n\n\n\nTry the rank-ordered logit distribution. Good luck!\n\n\n\nThis is a whole area of statistics, but you can get a long way by transforming compositional measurements to unconstrained space using a log-ratio function.\n\n\n\n\nIn a regression model the function \\(T(x, \\theta)\\) encodes the modeller’s knowledge about how the measurement targets depend on the covariates and parameters. The simplest, and by far most common, way to do this is with a linear model.\nA linear model assumes that the expected value of the measurable, i.e. \\(\\hat{y}_{\\text{dep}}\\), depends on a weighted sum of the covariates \\(x\\). For example, we might have\n\\[\n\\hat{y}_{\\text{dep}} = x\\beta\n\\]\nWhere \\(\\beta\\) is a vector of weights.\n\nNote that this formulation allows for an intercept, i.e. a weight that applies to all measurements, via inclusion of a dummy variable in \\(x\\) whose value is 1 for all measurements.\n\nTo accommodate constrained measurement models without changing the approach too much, linear models often add a “link” function that transforms the unconstrained term \\(x\\beta\\) to match the constrained term \\(\\hat{y}_{\\text{dep}}\\). Models with this form are called “generalised linear models” or “GLM”s. For example, here is a poisson GLM for describing count data, where the link function is the natural logarithm:\n\\[\n\\begin{align*}\n\\hat{y}_{\\text{dep}} = \\ln(x\\beta)\ny_{\\text{dep}} \\sim Poisson(\\hat{y}_{\\text{dep}})\n\\end{align*}\n\\]\n\n\nLinear models have a lot of hidden flexibility, as the modeller is free to transform the covariates however they like. You can and should make the most of this freedom. In particular, consider log-transforming any positive-constrained covariates.",
    "crumbs": [
      "Course materials",
      "Day 2 am: Regression and formula-based models"
    ]
  },
  {
    "objectID": "course_materials/day-2-am-regression.html#regression",
    "href": "course_materials/day-2-am-regression.html#regression",
    "title": "Day 2 am: Regression and formula-based models",
    "section": "",
    "text": "Recall from the previous session that one of the advantages of Bayesian statistical inference—aka using a sample to answer questions about a population in the form of probability statements—is that probability functions decompose into the following convenient form:\n\\[\np(y, \\theta) \\propto p(\\theta)p(y\\mid\\theta)\n\\]\nIn particular, we mentioned that the form \\(p(y\\mid\\theta)\\) is convenient for representing data generating processes.\nRegression is the main way to flesh out this idea: it provides specific ways to say, for data \\(y\\) and parameters \\(\\theta\\), what is the likelihood \\(p(y\\mid\\theta)\\).\nThe key idea of regression is to separate out some components of \\(y\\) called “covariates”, or “independent” variables, and typically denoted \\(x\\). Here we will use the term \\(y_{\\text{dep}}\\) to refer to the other members of \\(y\\), typically called “variates” or “dependent variables” and used to represent things that are measured in an experiment.\n\nThe rest of this course, an most statistics notation, typically omits the subscript \\(_{\\text{dep}}\\) in \\(y_{\\text{dep}}\\) and \\(\\hat{y}_{\\text{dep}}\\), as there is usually no need to refer to the full data \\(y=\\{x, y_{dep}\\}\\).\n\nWith this split made, the next step in regression modelling is to define a way to turn the covariates into a summary statistic, then connect this statistic probabilistically with \\(y_{\\text{dep}}\\). In mathematical notation, this means that a regression model has this form:\n\\[\np(y\\mid\\theta) = p(y_{\\text{dep}}\\mid T(x, \\theta), \\theta)\n\\]\nwhere \\(T\\) is a deterministic function that maps any \\(x\\) and \\(\\theta\\) to a summary statistic.\nA popular approach, which we will concentrate on in this course, is for the summary statistic \\(T(x, \\theta)=\\hat{y}_{\\text{dep}}(x, \\theta)\\) to be an estimate of the most likely, or “expected”, value of \\(y_{dep}\\). Alternatively, in quantile regression the summary statistic estimates an extreme value of \\(y_{dep}\\).\nFormulating \\(p(y\\mid\\theta)\\) up in this way allows a regression modeller to separately create a deterministic model of the underlying process and a probabilistic model of the measurement process. This separation is very convenient!\nBeing able to choose any deterministic function \\(T\\) to represent the relationship between \\(x\\), \\(\\theta\\) and \\(y_{dep}\\) allows the modeller a lot of freedom to represent domain knowledge. For example, \\(T\\) might encode a kinetic model connecting experimental conditions with things we can measure in a bioreactor.\nOn the other hand, writing down a function \\(p(y_{\\text{dep}}\\mid T(x, \\theta), \\theta)\\) is often easier than directly specifying a likelihood function \\(p(y\\mid\\theta)\\). The former, regression-based formulation is natural for representing how noisy measurements work. For example, regression models often represent measurements using the normal distribution:\n\\[\n\\begin{align*}\n\\theta &= \\theta_1, ..., \\theta_k, \\sigma \\\\\nT(x, \\theta) &= T(x, \\theta_1, ..., \\theta_k) = \\hat{y}_{\\text{dep}}\\\\\np(y_{\\text{dep}}\\mid T(x, \\theta), \\theta) &= N(y_{\\text{dep}}\\mid \\hat{y}_{\\text{dep}}, \\sigma)\n\\end{align*}\n\\]\nIn this equation \\(N\\) indicates the normal probability density function:\n\\[\nN(y_{\\text{dep}}\\mid\\hat{y}_{\\text{dep}},\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp{-\\frac{(y_{\\text{dep}}-\\hat{y}_{\\text{dep}})^2}{2\\sigma^2}}\n\\]\nTo get an intuition for why this makes sense as a way to represent a measurement, consider the following plot of this function:\n\nNote that, as we usually expect for a measurement, the density is highest when the measured and expected values are the same, and smoothly and symmetrically decreases with this distance. The accuracy of the measurement can be captured by the parameter \\(\\sigma\\), as shown by comparing the blue and orange lines.\n\n\nHere are some rules of thumb for representing measurements using probability distributions.\nThe most important thing is to consider are natural constraints: where does the measurement have to live?\n\n\nIf both measureable and measurement can in principle live on any the real line, the Normal regression model presented above is usually a good starting point. Many standard statistical methods explicitly or implicitly assume such a model.\nIf your unconstrained measurements come in batches, consider whether they are likely to be correlated, so that the value of one batch component could be informative about the value of another. If so, you may want to use a multivariate normal distribution to model your measurements.\nIf, as happens quite often, your unconstrained measurements potentially include outliers, they may be better described using a measurement distribution with heavier tails than the normal distribution, such as the student-T distribution.\nIf your unconstrained measurements are skewed, so that errors in one direction are more likely than the other, consider modelling them with a skew-normal distribution.\n\n\n\nWe often want to measure things that cannot possibly be negative, like concentrations or temperatures. This kind of measurement is often not well described by the normal distribution.\nFirst, note that the normal distribution has support across the whole real number line, half of which is inaccessible to a non-negative measurement. Modelling non-negative measurements using the normal distribution therefore necessarily involves allocating probability mass to something structurally impossible. How big of a problem this is in practice depends on the amount of probability mass misallocated: this in turn depends on the distance in measurement standard deviations from \\(\\hat{y}_{\\text{dep}}\\) to zero. As a general rule of thumb, if this distance is less than 3 standard deviations for any measurement, there is a potential problem.\nSecond, note that the normal probability density function is symmetrical: the density decreases at the same rate both up and down from \\(y_{\\text{dep}}-\\hat{y}_{\\text{dep}}=0\\). This behaviour is desirable when an error gets less likely proportionally to its absolute size. However non-negative measurement errors are often naturally expressed relatively, not absolutely. If you usually talk about your errors in terms like “+/- 10%” or similar, an unconstrained probability distribution is probably a bad fit.\nFor these reasons, when modelling non-negative measurements, it is often a good idea to use a probability distribution whose support lies only on the non-negative real line. This can often easily be done by log-transforming the measurements and then using an unconstrained measurement distribution centred at the logarithm of \\(\\hat{y}_{\\text{dep}}\\).\n\n\n\nTry transforming the measurements to unconstrained space using the inverse hyperbolic tangent function.\n\n\n\nUse the poisson distribution.\n\n\n\nTry the rank-ordered logit distribution. Good luck!\n\n\n\nThis is a whole area of statistics, but you can get a long way by transforming compositional measurements to unconstrained space using a log-ratio function.\n\n\n\n\nIn a regression model the function \\(T(x, \\theta)\\) encodes the modeller’s knowledge about how the measurement targets depend on the covariates and parameters. The simplest, and by far most common, way to do this is with a linear model.\nA linear model assumes that the expected value of the measurable, i.e. \\(\\hat{y}_{\\text{dep}}\\), depends on a weighted sum of the covariates \\(x\\). For example, we might have\n\\[\n\\hat{y}_{\\text{dep}} = x\\beta\n\\]\nWhere \\(\\beta\\) is a vector of weights.\n\nNote that this formulation allows for an intercept, i.e. a weight that applies to all measurements, via inclusion of a dummy variable in \\(x\\) whose value is 1 for all measurements.\n\nTo accommodate constrained measurement models without changing the approach too much, linear models often add a “link” function that transforms the unconstrained term \\(x\\beta\\) to match the constrained term \\(\\hat{y}_{\\text{dep}}\\). Models with this form are called “generalised linear models” or “GLM”s. For example, here is a poisson GLM for describing count data, where the link function is the natural logarithm:\n\\[\n\\begin{align*}\n\\hat{y}_{\\text{dep}} = \\ln(x\\beta)\ny_{\\text{dep}} \\sim Poisson(\\hat{y}_{\\text{dep}})\n\\end{align*}\n\\]\n\n\nLinear models have a lot of hidden flexibility, as the modeller is free to transform the covariates however they like. You can and should make the most of this freedom. In particular, consider log-transforming any positive-constrained covariates.",
    "crumbs": [
      "Course materials",
      "Day 2 am: Regression and formula-based models"
    ]
  },
  {
    "objectID": "course_materials/day-1-am-introduction.html",
    "href": "course_materials/day-1-am-introduction.html",
    "title": "Day 1 am: Bayesian Inference",
    "section": "",
    "text": "The aim of today’s morning session is to understand Bayesian inference from a theoretical point of view, and to introduce a data analysis problem that motivates the course.\n\n\nBayesian statistical inference can be understood pretty well by looking separately at the two concepts “Bayesian” and “statistical inference”.\n\n\nThe word “Bayesian” comes from the statistician Thomas Bayes, who proved some theorems about conditional probability functions in the 18th century. In modern usage, the term “Bayesian” doesn’t really have much to do with the original Bayes; rather it means something like “to do with probability functions”, with the exact meaning varying depending on the specific context.\nMathematically, a probability function is a function \\(p: \\mathcal{S} \\rightarrow \\mathbb{R}_{\\geq 0}\\) where:\n\n\\(\\mathcal{S}\\) is an event space containing subsets of an arbitrary set \\(\\Omega\\) (formally, a \\(\\sigma\\) algebra).\n\\(p(\\Omega) = 1\\)\nIf \\(A, B \\in \\mathcal{S}\\) are disjoint (i.e. they have no members in common), then \\(p(A\\cup B) = p(A) + p(B)\\)\n\nIntuitively, probability functions describe more or less anything that can be measured. For example, a jug containing 1 unit of water\n\n\n\n\n\n\nFigure 1: A jug of water\n\n\n\nTo draw out the analogy a little and connect the mathematical definition with the intuition, consider:\n\nIn this case the set \\(\\Omega\\) corresponds to all the water inside the jug, modelled as a continuous set of points.\n\\(\\mathcal{S}\\) then represents any possible way of arranging all of the water. dividing the water in the jug into subsets. For example, pouring some of it out of the jug and into two cups.\nFor any \\(S\\in\\mathcal{S}\\), \\(p(S)\\) is just the amount of water that \\(S\\) contains, relative to the total amount \\(p(\\Omega) = 1\\). For example, perhaps cup \\(A\\) contains \\(p(A)=0.4\\) units of water and similarly for the other cup, \\(p(B) = 0.2\\).\nNote that, as long as the cups do not contain the same water (i.e. they do not belong to a topologist and are not bath toys for a baby), subsets \\(A\\) and \\(B\\) are disjoint, so that the total amount of water poured out is \\(p(A\\cup B) = p(A) + p(B) =  0.6\\)\n\n\n\nBayesian epistemology is the idea that probability functions can describe belief or information. In other words, sometimes it is convenient to think about information as a thing that can be measured and shared around, like water. For example, we might use the cups \\(A\\) and \\(B\\) to represent some mutually exclusive propositions. Then we could represent the information “definitely B” by dividing the belief up like this:\n\nWe could also use this method to represent some other beliefs:\n“Not sure if A or B”:\n\n“B a bit more plausible than A”:\n\nInteresting philosophical discussions can be had about whether this kind of analogy can describe any information. My personal favourite is the book “Patterns of Plausible Inference” (Pólya 1990). However, for Bayesian statistics to be useful we only need the weaker proposition that the analogy sort of works sometimes. I think this is pretty hard to dispute, as shown by how often people say things like “probably” or “100%” to describe information.\n\n\n\n\nThe problem of finding things out about a population by examining a sample from the population encompasses statistical inference. This is something we all do all the time, which shows that you really know how to do statistical inference already: doing this course may not teach you something new so much as make your existing knowledge easier to articulate! An example of sample to population inference that you may have experience with is tasting a spoonful from a pot of soup:\n\n\n\n\n\n\nFigure 2: A nice soup: here is the recipe\n\n\n\nTypically, salt mixes pretty well into the soup, so it is pretty safe to say that the salt concentration of the whole pot of soup will be about the same as the concentration in the spoon. On the other hand, if your goal was to establish the total number of carrots in the pot per unit volume, counting the number in a spoonful might not be so reliable!\nThe aim of theoretical statistical inference is to construct systematic rules for sample-to-population reasoning of this type. For example, we might use the following rule:\n\nIt is safe to say that the concentration of a thing in the spoon is about the same as the concentration in the pot, provided there are at least 1000 particles of the thing in the spoon.\n\n\n\n\n\n\n\nExercise\n\n\n\nCan you think of any problems with this rule?\n\n\n\n\n\nEquipped with the concepts “Bayesian” and “statistical inference”, we can now make a definition of “Bayesian statistical inference”:\nBayesian inference is sample-to-population inference that results in statements about a probability function, i.e. an assignment of numbers to elements of an event space.\nFor example, faced with the tasting problem, these statistical inferences are “Bayesian”\n\nspoon \\(\\rightarrow\\) \\(p(\\text{soup not salty})\\) = 99.9%\nspoon \\(\\rightarrow\\) \\(p(\\text{no carrots in soup})\\) = 95.1%\n\nTo illustrate that other forms of statistical inference are possible, consider these non-Bayesian inferences:\n\nspoon \\(\\rightarrow\\) Best estimate of salt concentration is 0.1mol/l\n\\(p_{\\text{carrot hypothesis}}(\\text{spoon with fewer carrots than this}) = 4.9\\%\\) \\(\\rightarrow\\) There are no carrots in the pot!\n\nThe first inference is non-Bayesian because the result—a best estimate of the population salt concentration—is not a probability.\n\n\n\n\n\n\nSomething to think about\n\n\n\nHow might we get an estimate of the population concentration from a Bayesian inference, if that was what we wanted?\n\n\nThe second inference has the same form as a null-hypothesis significance test, a statistical inference method you may be familiar with. The inference kind of looks probability-like, so you might wonder if it is Bayesian according to our definition. The answer is no! There is a probability statement on the left hand side of the inference, i.e. the statement that, according to a probability function representing the hypothesis that there are carrots in the pot, it would be unlikely to see this few carrots. However, according to our definition Bayesian inference requires a probability statement on the right hand side.\n\n\n\nSince the special thing about Bayesian inference, compared with other ways of doing statistical inference is that it outputs a statement about a probability function, the reasons for choosing Bayesian inference also have to do with the features of probabilities.\n\n\nIt is straightforward to interpret statements about probabilities in terms of information and plausible reasoning. For example, after doing a Bayesian inference, one can say things like “According to my model, proposition x…”\n\n“…is highly plausible.”\n“…is more plausible than y.”\n“…is neither ruled in or out by the available data. There just isn’t enough information for firm conclusions about x.”\n\nIn contrast, non-Bayesian statistical inferences can be trickier to interpret.\nFor a lot more about this and other connections between Bayesian inference, information and plausible reasoning, check out (Jaynes 2003).\n\n\n\nProbability theory is a mature and well-developed branch of mathematics. This makes probability functions a good choice for the output of a statistical inference for several reasons. First, since so much work has already been done, it is rare that Bayesian inference is blocked by the need to develop new mathematical theory. In fact, the theoretical apparatus of Bayesian inference was already available to Pierre-Simon Laplace: the Bayesian inference that he practised before the French revolution is essentially the same as you will learn in this course.\n\n\n\n\n\n\n(https://en.wikipedia.org/wiki/Pierre-Simon_Laplace)\n\n\n\n\nFigure 3: Laplace, who did Bayesian inference in the 1780s\n\n\n\nSecond, the maturity of probability theory means that Bayesian statistical inference is compatible with a wide range of related tools, and in particular Bayesian decision theory. Whereas users of newer statistical frameworks must do some original work to justify what they want to do with their inferences, Bayesian inference practitioners can simply specify a utility function and then plug in to the existing theory.\n\n\n\nProbabilities decompose nicely according to Bayes’s theorem:\n\\[\np(\\theta, y) = p(\\theta)p(y\\mid\\theta)\n\\]\nThis expression is nice because the components have natural interpretations:\n\n\\(p(\\theta)\\), aka “prior distribution”: nice form for background information, e.g. anything non-experimental\n\\(p(y\\mid\\theta)\\), aka “sampling distribution”, “data distribution”, “likelihood function”: a nice form for describing the data-generating process\n\\(p(\\theta, y)\\), aka “joint probability distribution” a single function that encapsulates the whole model\n\n\nBayes’s theorem is typically presented in these equivalent forms:\n\\[\np(\\theta\\mid y) = \\frac{p(\\theta)p(y\\mid\\theta)}{p(y)}\n\\]\nor\n\\[\np(\\theta\\mid y) \\propto p(\\theta)p(y\\mid\\theta)\n\\]\n\n\n\n\n\nBayesian inference is not the best choice for every data analysis problem: there are a number of solid practical reasons not to use Bayesian inference that you should be aware of.\n\n\nThe biggest reason not to use Bayesian inference is its often-high computational cost. The section on MCMC will touch on the specifics of this, but here is the short version. Suppose we are interested in some unknown quantity \\(X\\), perhaps the concentration of salt molecules in the bowl of soup. We typically want to know something like “Is the amount of salt correct”, i.e. is \\(X\\) greater than some number \\(l\\) and less than some other number \\(h\\). The way to answer this question using Bayesian inference is to first taste a spoonful, then, probably using Bayes’s theorem, write down a probability density function \\(p:\\mathcal{X}\\rightarrow\\mathbb{R}^{+}\\) that assigns a number to any possible salt concentration. To answer our question, we have to integrate our function \\(p\\) between \\(l\\) and \\(h\\):\n\\[\n\\text{Probability that the saltiness is correct} = \\int_{l}^{h}p(x)dx\n\\]\nThis is the problem: integration is difficult! Many probability functions accurately describe experimental setups, but are impossible to differentiate analytically. In such cases doing Bayesian inference requires expensively solving the integration problem numerically, using methods like Monte Carlo integration. This case is typical, so in practice Bayesian inference requires expensive computation.\nThe practical upshot of this problem is that you may not have the computational resources or time to solve your data analysis problem using Bayesian inference. If so, you might be better off using non-Bayesian statistical inference, which may actually produce an answer. Here are some rules of thumb for predicting whether you are in such a situation, assuming you are not a billionaire and want to use general-purpose methods:\n\nMore than ten million unknown parameters that need to be estimated at the same time\nMore than one hundred million data points must be taken into account\nMore than one hundred unknown discrete parameters need to be estimated (this includes qualitatively different models being jointly compared or mixture distribution components)\n\n\n\n\n\n\n\n\n\n\nFigure 4: Prospectors. Are you doing inference or prospecting? Sometimes the goal is not to perfectly survey the landscape, but to find gold quickly.\n\n\n\nAs we found out above, statistical inference aims to answer questions about a population based on a sample. That isn’t the only thing you can do with samples! Often we aren’t primarily interested in knowing facts about the population, but rather want to use the information in the sample to get something: maybe a more optimal set of numbers, maybe any set of numbers that satisfies some qualitative condition.\nI like to call this kind of use for data “prospecting”, in the sense of exploring an area looking for mineral deposits. In a gold rush, prospectors typically want to quickly and cheaply discover and extract any gold in a sample area, then choose a good area to prospect next. Another appropriate term might be “optimisation”, but I think that one under-emphasises the quite common case where the goal is to satisfy some conditions rather than get the best possible score on a metric.\nThe line between inference and prospecting is blurry, as inference is rarely done entirely for its own sake: usually the ultimate goal is to do something useful with the inferences. Conversely, it is rare for prospecting not to answer any questions about the un-sampled population: this would only happen with a totally random search. However, I still think the distinction is helpful because it can help answer the question whether or not to use Bayesian inference.\nIf your data-analysis problem feels more like prospecting, you may want to use Bayesian inference. For example, Bayesian optimisation, which we will explore later, is a well-tested and widely-adopted prospecting method based on Bayesian inference. On the other hand, it may be faster or cheaper to use a non-Bayesian method.\n\n\n\nThe statistics wars of the 1980s and 1990s are long since finished and mostly forgotten, but Bayesian inference is still unfamiliar to many people and communities. As a result, it is often easier to use non-Bayesian inference, thereby avoiding the effort of explaining and justifying a new statistics thing.If Bayesian and non-Bayesian inference would both produce the same result in any case, this benefit my outweigh any benefits from using Bayesian inference. If all of these conditions are satisfied, you may be in such a situation:\n\nInformation other than the measurements has little relevance.\nThe measurements are structurally simple: for example there aren’t any groups of measurements that systematically differ from other groups.\nAny decisions that need to be made based on the inference are qualitative, yes-or-no type decisions.\nThe experiment is likely to be conclusive one way or the other.\n\nThis is quite a high bar because, as this course will show, it’s really not that hard to explain Bayesian inference!\n\n\n\n\n\n\n\n\nBox and Tiao (1992, Ch. 1.1) (available from dtu findit) gives a nice explanation of statistical inference in general and why Bayes.\nGelman et al. (2020) is a great textbook. The first chapter in particular gives a very nice presentation of the relevant mathematics.\nHistorical interest:\n\nLaplace (1986) and Stigler (1986)\nJaynes (2003) Preface",
    "crumbs": [
      "Course materials",
      "Day 1 am: Bayesian Inference"
    ]
  },
  {
    "objectID": "course_materials/day-1-am-introduction.html#bayesian-statistical-inference",
    "href": "course_materials/day-1-am-introduction.html#bayesian-statistical-inference",
    "title": "Day 1 am: Bayesian Inference",
    "section": "",
    "text": "Bayesian statistical inference can be understood pretty well by looking separately at the two concepts “Bayesian” and “statistical inference”.\n\n\nThe word “Bayesian” comes from the statistician Thomas Bayes, who proved some theorems about conditional probability functions in the 18th century. In modern usage, the term “Bayesian” doesn’t really have much to do with the original Bayes; rather it means something like “to do with probability functions”, with the exact meaning varying depending on the specific context.\nMathematically, a probability function is a function \\(p: \\mathcal{S} \\rightarrow \\mathbb{R}_{\\geq 0}\\) where:\n\n\\(\\mathcal{S}\\) is an event space containing subsets of an arbitrary set \\(\\Omega\\) (formally, a \\(\\sigma\\) algebra).\n\\(p(\\Omega) = 1\\)\nIf \\(A, B \\in \\mathcal{S}\\) are disjoint (i.e. they have no members in common), then \\(p(A\\cup B) = p(A) + p(B)\\)\n\nIntuitively, probability functions describe more or less anything that can be measured. For example, a jug containing 1 unit of water\n\n\n\n\n\n\nFigure 1: A jug of water\n\n\n\nTo draw out the analogy a little and connect the mathematical definition with the intuition, consider:\n\nIn this case the set \\(\\Omega\\) corresponds to all the water inside the jug, modelled as a continuous set of points.\n\\(\\mathcal{S}\\) then represents any possible way of arranging all of the water. dividing the water in the jug into subsets. For example, pouring some of it out of the jug and into two cups.\nFor any \\(S\\in\\mathcal{S}\\), \\(p(S)\\) is just the amount of water that \\(S\\) contains, relative to the total amount \\(p(\\Omega) = 1\\). For example, perhaps cup \\(A\\) contains \\(p(A)=0.4\\) units of water and similarly for the other cup, \\(p(B) = 0.2\\).\nNote that, as long as the cups do not contain the same water (i.e. they do not belong to a topologist and are not bath toys for a baby), subsets \\(A\\) and \\(B\\) are disjoint, so that the total amount of water poured out is \\(p(A\\cup B) = p(A) + p(B) =  0.6\\)\n\n\n\nBayesian epistemology is the idea that probability functions can describe belief or information. In other words, sometimes it is convenient to think about information as a thing that can be measured and shared around, like water. For example, we might use the cups \\(A\\) and \\(B\\) to represent some mutually exclusive propositions. Then we could represent the information “definitely B” by dividing the belief up like this:\n\nWe could also use this method to represent some other beliefs:\n“Not sure if A or B”:\n\n“B a bit more plausible than A”:\n\nInteresting philosophical discussions can be had about whether this kind of analogy can describe any information. My personal favourite is the book “Patterns of Plausible Inference” (Pólya 1990). However, for Bayesian statistics to be useful we only need the weaker proposition that the analogy sort of works sometimes. I think this is pretty hard to dispute, as shown by how often people say things like “probably” or “100%” to describe information.\n\n\n\n\nThe problem of finding things out about a population by examining a sample from the population encompasses statistical inference. This is something we all do all the time, which shows that you really know how to do statistical inference already: doing this course may not teach you something new so much as make your existing knowledge easier to articulate! An example of sample to population inference that you may have experience with is tasting a spoonful from a pot of soup:\n\n\n\n\n\n\nFigure 2: A nice soup: here is the recipe\n\n\n\nTypically, salt mixes pretty well into the soup, so it is pretty safe to say that the salt concentration of the whole pot of soup will be about the same as the concentration in the spoon. On the other hand, if your goal was to establish the total number of carrots in the pot per unit volume, counting the number in a spoonful might not be so reliable!\nThe aim of theoretical statistical inference is to construct systematic rules for sample-to-population reasoning of this type. For example, we might use the following rule:\n\nIt is safe to say that the concentration of a thing in the spoon is about the same as the concentration in the pot, provided there are at least 1000 particles of the thing in the spoon.\n\n\n\n\n\n\n\nExercise\n\n\n\nCan you think of any problems with this rule?\n\n\n\n\n\nEquipped with the concepts “Bayesian” and “statistical inference”, we can now make a definition of “Bayesian statistical inference”:\nBayesian inference is sample-to-population inference that results in statements about a probability function, i.e. an assignment of numbers to elements of an event space.\nFor example, faced with the tasting problem, these statistical inferences are “Bayesian”\n\nspoon \\(\\rightarrow\\) \\(p(\\text{soup not salty})\\) = 99.9%\nspoon \\(\\rightarrow\\) \\(p(\\text{no carrots in soup})\\) = 95.1%\n\nTo illustrate that other forms of statistical inference are possible, consider these non-Bayesian inferences:\n\nspoon \\(\\rightarrow\\) Best estimate of salt concentration is 0.1mol/l\n\\(p_{\\text{carrot hypothesis}}(\\text{spoon with fewer carrots than this}) = 4.9\\%\\) \\(\\rightarrow\\) There are no carrots in the pot!\n\nThe first inference is non-Bayesian because the result—a best estimate of the population salt concentration—is not a probability.\n\n\n\n\n\n\nSomething to think about\n\n\n\nHow might we get an estimate of the population concentration from a Bayesian inference, if that was what we wanted?\n\n\nThe second inference has the same form as a null-hypothesis significance test, a statistical inference method you may be familiar with. The inference kind of looks probability-like, so you might wonder if it is Bayesian according to our definition. The answer is no! There is a probability statement on the left hand side of the inference, i.e. the statement that, according to a probability function representing the hypothesis that there are carrots in the pot, it would be unlikely to see this few carrots. However, according to our definition Bayesian inference requires a probability statement on the right hand side.\n\n\n\nSince the special thing about Bayesian inference, compared with other ways of doing statistical inference is that it outputs a statement about a probability function, the reasons for choosing Bayesian inference also have to do with the features of probabilities.\n\n\nIt is straightforward to interpret statements about probabilities in terms of information and plausible reasoning. For example, after doing a Bayesian inference, one can say things like “According to my model, proposition x…”\n\n“…is highly plausible.”\n“…is more plausible than y.”\n“…is neither ruled in or out by the available data. There just isn’t enough information for firm conclusions about x.”\n\nIn contrast, non-Bayesian statistical inferences can be trickier to interpret.\nFor a lot more about this and other connections between Bayesian inference, information and plausible reasoning, check out (Jaynes 2003).\n\n\n\nProbability theory is a mature and well-developed branch of mathematics. This makes probability functions a good choice for the output of a statistical inference for several reasons. First, since so much work has already been done, it is rare that Bayesian inference is blocked by the need to develop new mathematical theory. In fact, the theoretical apparatus of Bayesian inference was already available to Pierre-Simon Laplace: the Bayesian inference that he practised before the French revolution is essentially the same as you will learn in this course.\n\n\n\n\n\n\n(https://en.wikipedia.org/wiki/Pierre-Simon_Laplace)\n\n\n\n\nFigure 3: Laplace, who did Bayesian inference in the 1780s\n\n\n\nSecond, the maturity of probability theory means that Bayesian statistical inference is compatible with a wide range of related tools, and in particular Bayesian decision theory. Whereas users of newer statistical frameworks must do some original work to justify what they want to do with their inferences, Bayesian inference practitioners can simply specify a utility function and then plug in to the existing theory.\n\n\n\nProbabilities decompose nicely according to Bayes’s theorem:\n\\[\np(\\theta, y) = p(\\theta)p(y\\mid\\theta)\n\\]\nThis expression is nice because the components have natural interpretations:\n\n\\(p(\\theta)\\), aka “prior distribution”: nice form for background information, e.g. anything non-experimental\n\\(p(y\\mid\\theta)\\), aka “sampling distribution”, “data distribution”, “likelihood function”: a nice form for describing the data-generating process\n\\(p(\\theta, y)\\), aka “joint probability distribution” a single function that encapsulates the whole model\n\n\nBayes’s theorem is typically presented in these equivalent forms:\n\\[\np(\\theta\\mid y) = \\frac{p(\\theta)p(y\\mid\\theta)}{p(y)}\n\\]\nor\n\\[\np(\\theta\\mid y) \\propto p(\\theta)p(y\\mid\\theta)\n\\]\n\n\n\n\n\nBayesian inference is not the best choice for every data analysis problem: there are a number of solid practical reasons not to use Bayesian inference that you should be aware of.\n\n\nThe biggest reason not to use Bayesian inference is its often-high computational cost. The section on MCMC will touch on the specifics of this, but here is the short version. Suppose we are interested in some unknown quantity \\(X\\), perhaps the concentration of salt molecules in the bowl of soup. We typically want to know something like “Is the amount of salt correct”, i.e. is \\(X\\) greater than some number \\(l\\) and less than some other number \\(h\\). The way to answer this question using Bayesian inference is to first taste a spoonful, then, probably using Bayes’s theorem, write down a probability density function \\(p:\\mathcal{X}\\rightarrow\\mathbb{R}^{+}\\) that assigns a number to any possible salt concentration. To answer our question, we have to integrate our function \\(p\\) between \\(l\\) and \\(h\\):\n\\[\n\\text{Probability that the saltiness is correct} = \\int_{l}^{h}p(x)dx\n\\]\nThis is the problem: integration is difficult! Many probability functions accurately describe experimental setups, but are impossible to differentiate analytically. In such cases doing Bayesian inference requires expensively solving the integration problem numerically, using methods like Monte Carlo integration. This case is typical, so in practice Bayesian inference requires expensive computation.\nThe practical upshot of this problem is that you may not have the computational resources or time to solve your data analysis problem using Bayesian inference. If so, you might be better off using non-Bayesian statistical inference, which may actually produce an answer. Here are some rules of thumb for predicting whether you are in such a situation, assuming you are not a billionaire and want to use general-purpose methods:\n\nMore than ten million unknown parameters that need to be estimated at the same time\nMore than one hundred million data points must be taken into account\nMore than one hundred unknown discrete parameters need to be estimated (this includes qualitatively different models being jointly compared or mixture distribution components)\n\n\n\n\n\n\n\n\n\n\nFigure 4: Prospectors. Are you doing inference or prospecting? Sometimes the goal is not to perfectly survey the landscape, but to find gold quickly.\n\n\n\nAs we found out above, statistical inference aims to answer questions about a population based on a sample. That isn’t the only thing you can do with samples! Often we aren’t primarily interested in knowing facts about the population, but rather want to use the information in the sample to get something: maybe a more optimal set of numbers, maybe any set of numbers that satisfies some qualitative condition.\nI like to call this kind of use for data “prospecting”, in the sense of exploring an area looking for mineral deposits. In a gold rush, prospectors typically want to quickly and cheaply discover and extract any gold in a sample area, then choose a good area to prospect next. Another appropriate term might be “optimisation”, but I think that one under-emphasises the quite common case where the goal is to satisfy some conditions rather than get the best possible score on a metric.\nThe line between inference and prospecting is blurry, as inference is rarely done entirely for its own sake: usually the ultimate goal is to do something useful with the inferences. Conversely, it is rare for prospecting not to answer any questions about the un-sampled population: this would only happen with a totally random search. However, I still think the distinction is helpful because it can help answer the question whether or not to use Bayesian inference.\nIf your data-analysis problem feels more like prospecting, you may want to use Bayesian inference. For example, Bayesian optimisation, which we will explore later, is a well-tested and widely-adopted prospecting method based on Bayesian inference. On the other hand, it may be faster or cheaper to use a non-Bayesian method.\n\n\n\nThe statistics wars of the 1980s and 1990s are long since finished and mostly forgotten, but Bayesian inference is still unfamiliar to many people and communities. As a result, it is often easier to use non-Bayesian inference, thereby avoiding the effort of explaining and justifying a new statistics thing.If Bayesian and non-Bayesian inference would both produce the same result in any case, this benefit my outweigh any benefits from using Bayesian inference. If all of these conditions are satisfied, you may be in such a situation:\n\nInformation other than the measurements has little relevance.\nThe measurements are structurally simple: for example there aren’t any groups of measurements that systematically differ from other groups.\nAny decisions that need to be made based on the inference are qualitative, yes-or-no type decisions.\nThe experiment is likely to be conclusive one way or the other.\n\nThis is quite a high bar because, as this course will show, it’s really not that hard to explain Bayesian inference!",
    "crumbs": [
      "Course materials",
      "Day 1 am: Bayesian Inference"
    ]
  },
  {
    "objectID": "course_materials/day-1-am-introduction.html#things-to-read",
    "href": "course_materials/day-1-am-introduction.html#things-to-read",
    "title": "Day 1 am: Bayesian Inference",
    "section": "",
    "text": "Box and Tiao (1992, Ch. 1.1) (available from dtu findit) gives a nice explanation of statistical inference in general and why Bayes.\nGelman et al. (2020) is a great textbook. The first chapter in particular gives a very nice presentation of the relevant mathematics.\nHistorical interest:\n\nLaplace (1986) and Stigler (1986)\nJaynes (2003) Preface",
    "crumbs": [
      "Course materials",
      "Day 1 am: Bayesian Inference"
    ]
  },
  {
    "objectID": "course_materials/index.html",
    "href": "course_materials/index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome!\nThis is a course about Bayesian statistics, targeted at computational biologists\nThe course currently takes place physically over three weeks in the summer at DTU Biosustain. If you are taking or want to take that course, congratulations you are in the right place! If not, you may still find something interesting here!\nThe aim of the course is to teach students with a background in computational biology how to:\n\nDescribe Bayesian inference in the abstract\nAssess whether Bayesian inference is a good fit for a problem\nFormulate custom measurement models to describe biological problems\nSolve statistical modelling problems by iteratively fitting and evaluating a series of models\nChoose appropriate software for a Bayesian statistical modelling project\nUnderstand gradient-based MCMC techniques and their failure modes\nFit biological models with embedded ODE systems, root-finding problems and Gaussian processes.\nPerform Bayesian optimisation\nUnderstand recent trends in Bayesian statistical inference\n\nThe learning material consists of 20 sessions, each intended to take up half a day over two weeks. The third week of the course is set aside for the students to complete a project. For the first two weeks, the first half-day will generally cover theoretical topics, with the second consisting of practical, computer-based tasks. Here is the rough plan:\n\nDay 1. am: Bayesian statistical inference, motivating example\nDay 1. pm: Set up computers (Python, uv, git, editor)\nDay 2. am: Regression, formula-based models and why they aren’t enough\nDay 2. pm: Some regression examples, bambi\nDay 3. am: Markov Chain Monte Carlo, why you still probably want to use it.\nDay 3. pm: A Bayesian statistics stack for computational biology\nDay 4. am: What to do with MCMC output?\nDay 4. pm: Worked examples: - convergence - divergent transitions - model comparison - change of variables causing bad model\nDay 5. am: Bayesian workflow\nDay 5. pm: Workflow example with automation\nDay 6. am: Ordinary differential equations\nDay 6. pm: Diffrax, fermentation examples\nDay 7. am: Algebraic equation systems, implicit differentiation\nDay 7. pm: Optimistix, steady state example, grapevine\nDay 8. am: Gaussian processes, HSGPs\nDay 8. pm: GP example\nDay 9. am: Bayesian optimisation\nDay 9. pm: BO example\nDay 10. am: Fun new Bayesian trends - Probabilistic numerics - Amortised Bayesian inference - New MCMC algorithms - Control - Normalising flows\nDay 10. pm: examples",
    "crumbs": [
      "Admin",
      "Welcome!"
    ]
  },
  {
    "objectID": "course_materials/day-1-pm-setup.html",
    "href": "course_materials/day-1-pm-setup.html",
    "title": "Day 1 pm: Set up a suitable computer environment",
    "section": "",
    "text": "The aim for this half day is to make sure everyone has a computer environment where they can do the course.\n\n\nYou should have a way to edit arbitrary code files on your computer. Ideally it should have special setup for editing Python files with e.g. syntax highlighting.\nIf in doubt, VS code is always a good option.\n\n\n\nYou should have a terminal emulator that you can use to run command line programs.\nYour computer probably already has one of these:\n\nLinux: you probably already have one?\nmacOS: The computer comes with a terminal emulator called “terminal”. Plenty of others are available, many people really like iterm2. My favourite is Wezterm.\nWindows: I think PowerShell is the most popular\n\n\n\n\nuv is a Python dependency manager that can install Python for you.\nInstall it by following the instructions on the website. You should then be able to run this command in your terminal\n&gt; uv\nThe output should look something like this:\nAn extremely fast Python package manager.\n\nUsage: uv [OPTIONS] &lt;COMMAND&gt;\n\nCommands:\n    ...\nIf that works, try installing python (do this even if you already have python installed on your computer as it will likely make things easier later):\n&gt; uv python install\nTo execute a python file with uv:\n&gt; uv run my_python_file.py\nTo open a Python interpreter:\n&gt; uv run python\nTo start a new project:\nmkdir my_new_project\ncd my_new_project\nuv init\nTo install a Python package in the current project:\n&gt; uv add package_i_want_to_install\nTo install a Python-based application globally:\n&gt; uv tool install tool_i_want_to_install\nTo run a command with a package installed temporarily (e.g. in this case jupyter):\n&gt; uv run --with jupyter jupyter lab\n\n\n\nFirst make sure you have git installed by running this command in your terminal:\n&gt; git\nExpected output:\nusage: git [-v | --version] [-h | --help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]\n           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n           [--super-prefix=&lt;path&gt;] [--config-env=&lt;name&gt;=&lt;envvar&gt;]\n           &lt;command&gt; [&lt;args&gt;]\n\nThese are common Git commands used in various situations:\nIf that worked, navigate in your terminal to a place where you would like to put a new folder, then run this command:\n&gt; git clone https://github.com/dtu-qmcm/bayesian_statistics_for_computational_biology.git\nThere should now be a new folder called bayesian_statistics_for_computational_biology.\n\n\n\nNavigate into the folder bayesian_statistics_for_computational_biology and run this command:\n&gt; uv sync",
    "crumbs": [
      "Course materials",
      "Day 1 pm: Set up a suitable computer environment"
    ]
  },
  {
    "objectID": "course_materials/day-1-pm-setup.html#editor",
    "href": "course_materials/day-1-pm-setup.html#editor",
    "title": "Day 1 pm: Set up a suitable computer environment",
    "section": "",
    "text": "You should have a way to edit arbitrary code files on your computer. Ideally it should have special setup for editing Python files with e.g. syntax highlighting.\nIf in doubt, VS code is always a good option.",
    "crumbs": [
      "Course materials",
      "Day 1 pm: Set up a suitable computer environment"
    ]
  },
  {
    "objectID": "course_materials/day-1-pm-setup.html#terminal",
    "href": "course_materials/day-1-pm-setup.html#terminal",
    "title": "Day 1 pm: Set up a suitable computer environment",
    "section": "",
    "text": "You should have a terminal emulator that you can use to run command line programs.\nYour computer probably already has one of these:\n\nLinux: you probably already have one?\nmacOS: The computer comes with a terminal emulator called “terminal”. Plenty of others are available, many people really like iterm2. My favourite is Wezterm.\nWindows: I think PowerShell is the most popular",
    "crumbs": [
      "Course materials",
      "Day 1 pm: Set up a suitable computer environment"
    ]
  },
  {
    "objectID": "course_materials/day-1-pm-setup.html#uv",
    "href": "course_materials/day-1-pm-setup.html#uv",
    "title": "Day 1 pm: Set up a suitable computer environment",
    "section": "",
    "text": "uv is a Python dependency manager that can install Python for you.\nInstall it by following the instructions on the website. You should then be able to run this command in your terminal\n&gt; uv\nThe output should look something like this:\nAn extremely fast Python package manager.\n\nUsage: uv [OPTIONS] &lt;COMMAND&gt;\n\nCommands:\n    ...\nIf that works, try installing python (do this even if you already have python installed on your computer as it will likely make things easier later):\n&gt; uv python install\nTo execute a python file with uv:\n&gt; uv run my_python_file.py\nTo open a Python interpreter:\n&gt; uv run python\nTo start a new project:\nmkdir my_new_project\ncd my_new_project\nuv init\nTo install a Python package in the current project:\n&gt; uv add package_i_want_to_install\nTo install a Python-based application globally:\n&gt; uv tool install tool_i_want_to_install\nTo run a command with a package installed temporarily (e.g. in this case jupyter):\n&gt; uv run --with jupyter jupyter lab",
    "crumbs": [
      "Course materials",
      "Day 1 pm: Set up a suitable computer environment"
    ]
  },
  {
    "objectID": "course_materials/day-1-pm-setup.html#git",
    "href": "course_materials/day-1-pm-setup.html#git",
    "title": "Day 1 pm: Set up a suitable computer environment",
    "section": "",
    "text": "First make sure you have git installed by running this command in your terminal:\n&gt; git\nExpected output:\nusage: git [-v | --version] [-h | --help] [-C &lt;path&gt;] [-c &lt;name&gt;=&lt;value&gt;]\n           [--exec-path[=&lt;path&gt;]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=&lt;path&gt;] [--work-tree=&lt;path&gt;] [--namespace=&lt;name&gt;]\n           [--super-prefix=&lt;path&gt;] [--config-env=&lt;name&gt;=&lt;envvar&gt;]\n           &lt;command&gt; [&lt;args&gt;]\n\nThese are common Git commands used in various situations:\nIf that worked, navigate in your terminal to a place where you would like to put a new folder, then run this command:\n&gt; git clone https://github.com/dtu-qmcm/bayesian_statistics_for_computational_biology.git\nThere should now be a new folder called bayesian_statistics_for_computational_biology.",
    "crumbs": [
      "Course materials",
      "Day 1 pm: Set up a suitable computer environment"
    ]
  },
  {
    "objectID": "course_materials/day-1-pm-setup.html#python-packages",
    "href": "course_materials/day-1-pm-setup.html#python-packages",
    "title": "Day 1 pm: Set up a suitable computer environment",
    "section": "",
    "text": "Navigate into the folder bayesian_statistics_for_computational_biology and run this command:\n&gt; uv sync",
    "crumbs": [
      "Course materials",
      "Day 1 pm: Set up a suitable computer environment"
    ]
  }
]