{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "# Day 3 pm: Bayesian statistical software for computational biology\n",
        "\n",
        "To do a Bayesian statistical analysis you probably need to do the\n",
        "following things:\n",
        "\n",
        "-   Extracting, transforming, validating and saving data\n",
        "-   Model definition\n",
        "-   Model fitting\n",
        "-   Analysing and diagnosing fits\n",
        "-   Plotting\n",
        "-   Writing\n",
        "-   Orchestrating, aka tying everything together and making it\n",
        "    reproducible\n",
        "\n",
        "Software can help with all these activities, but it can be tricky to\n",
        "choose what software to use. This afternoon’s session will briefly\n",
        "review some of the available options and make some recommendations for\n",
        "our specific case of Bayesian statistics in computational biology.\n",
        "\n",
        "## Whistle-stop tour\n",
        "\n",
        "### ETL\n",
        "\n",
        "[ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) stands for\n",
        "“Extract, transform, load”.\n",
        "\n",
        "As well as being a good keyword for your CV, ETL roughly covers the\n",
        "things you need to do before thinking about modelling.\n",
        "\n",
        "For this you probably need to write some code in R, Python, some other\n",
        "high-level programming language, SQL or shell scripts. Out of these we\n",
        "will focus on Python in this course.\n",
        "\n",
        "In particular it is good to know how to use these Python packages:\n",
        "\n",
        "-   polars\n",
        "-   pandas\n",
        "-   numpy\n",
        "-   xarray\n",
        "-   pydantic\n",
        "-   patito (pydantic-style validation for polars dataframes)\n",
        "\n",
        "### Model definition\n",
        "\n",
        "The next task is to define models, typically quite a few.\n",
        "\n",
        "As we have already seen, to define a Bayesian statistical model it\n",
        "suffices to specify a probability density for any possible combination\n",
        "of data and parameters. For this you need a probabilistic programming\n",
        "language or PPL.\n",
        "\n",
        "We have already met one such framework, namely bambi, a good example of\n",
        "a formula-based probabilistic programming language. This kind of PPL can\n",
        "achieve a lot of succinctness, making it possible to define statistical\n",
        "models unambiguously with very little code, which is very useful when\n",
        "you want to easily spot differences between models. On the other hand,\n",
        "formula-based PPLs are inflexible: there are a lot of useful models that\n",
        "they can’t define, or for which doing so is very awkward, such as models\n",
        "whose data is not naturally tabular.\n",
        "\n",
        "A level more flexible are specialised Bayesian statistics-oriented\n",
        "probabilistic programming languages like PyMC, Stan and numpyro. These\n",
        "allow a lot more flexibility while still providing statistics-specific\n",
        "help like pre-computed distributions and transformations as well as\n",
        "helpful guardrails.\n",
        "\n",
        "Of these, Stan is my favourite for several reasons: - it is very\n",
        "flexible, allowing definition of almost any statistical model. - it has\n",
        "a large, active user and developer community - It is less abstract than\n",
        "the alternatives. For example, specifying a model involves explicitly\n",
        "calculating the joint density, i.e. saying how to perform a computation\n",
        "that outputs a number. This makes it much easier to think about\n",
        "performance compared with frameworks like PyMC where one defines models\n",
        "by declaring abstract random variable objects (though there are\n",
        "advantages to the abstraction in simpler cases).\n",
        "\n",
        "An even more flexible option, which we will explore in this course, is\n",
        "to use a modular approach based on JAX, a Python library that augments\n",
        "numpy and scipy with automatic differentiation, the key ingredient for\n",
        "Bayesian computation. Though it is increasingly popular for Bayesian\n",
        "statistics, JAX is a general scientific machine learning framework that\n",
        "doesn’t target this application specifically. A Bayesian linear\n",
        "regression model defined in JAX might look like this:\n",
        "\n",
        "``` python\n",
        "import jax \n",
        "from jax import numpy as jnp\n",
        "from jax.scipy.stats import norm\n",
        "\n",
        "def my_log_density(d: jax.Array, theta: dict[str, jax.Array]) -> float:\n",
        "    y, x = d\n",
        "    lprior = (\n",
        "        norm.lpdf(theta[\"alpha\"], loc=0.0, scale=1.0)\n",
        "        + norm.lpdf(theta[\"beta\"], loc=0.0, scale=1.0)\n",
        "        + norm.lpdf(theta[\"log_sigma\"], loc=0.0, scale=1.0)\n",
        "    )\n",
        "    yhat = theta[\"alpha\"] + x @ theta[\"beta\"]\n",
        "    sigma = jnp.exp(theta[\"log_sigma\"])\n",
        "    llik = norm.lpdf(y, loc=yhat, scale=sigma).sum()\n",
        "    return lprior + llik\n",
        "```\n",
        "\n",
        "This approach allows for even more flexibility than specialised Bayesian\n",
        "PPLs, at the cost of even more convenience. One such cost is the need to\n",
        "handle parameter constraints manually, as in the log-transform of\n",
        "`sigma` above. On the other hand, defining models as JAX functions\n",
        "allows us full control over not just what model we implement, but also\n",
        "how it is computed. Specifically, JAX makes it possible to run code on\n",
        "GPU/TPUs, achieve fine-grained parallelisation, access a wide range of\n",
        "MCMC samplers and numerical solvers and connect models with downstream\n",
        "applications like optimisation.\n",
        "\n",
        "The reason we will focus on this approach rather than traditional\n",
        "Bayesian PPLs is that its advantages are particularly pertinent to our\n",
        "intended topics including ODEs, Gaussian processes and Bayesian\n",
        "optimisation.\n",
        "\n",
        "### Model fitting\n",
        "\n",
        "The best general purpose method is adaptive Hamiltonian Monte Carlo.\n",
        "This algorithm is implemented by Stan, PyMC, numpyro, blackjax and more.\n",
        "\n",
        "In the last few years a lot of promising new MCMC algorithms have\n",
        "emerged, many of which are implemented in blackjax. [This\n",
        "page](https://blackjax-devs.github.io/blackjax/autoapi/blackjax/mcmc/index.html)\n",
        "lists what is currently available and [this\n",
        "book](https://blackjax-devs.github.io/sampling-book/) contains many\n",
        "helpful examples.\n",
        "\n",
        "Approximate Bayesian inference methods include variational inference.\n",
        "Stan and blackjax both implement these.\n",
        "\n",
        "Normalising flows [try flowMC](https://flowmc.readthedocs.io/en/main/)\n",
        "\n",
        "### Analysing and diagnosing fits\n",
        "\n",
        "[Arviz](https://python.arviz.org/en/stable/)!\n",
        "\n",
        "### Plotting\n",
        "\n",
        "Arviz and matplotlib.\n",
        "\n",
        "### Writing\n",
        "\n",
        "Quarto\n",
        "\n",
        "Jupyter\n",
        "\n",
        "Marimo\n",
        "\n",
        "Pandoc\n",
        "\n",
        "### Orchestrating\n",
        "\n",
        "Make\n",
        "\n",
        "Just\n",
        "\n",
        "shell script\n",
        "\n",
        "Nextflow\n",
        "\n",
        "snakemake\n",
        "\n",
        "## References\n",
        "\n",
        "(Štrumbelj et al. 2023)\n",
        "<https://elizavetasemenova.github.io/prob-epi/01_intro.html>\n",
        "\n",
        "Štrumbelj, Erik, Alexandre Bouchard-Côté, Jukka Corander, Andrew Gelman,\n",
        "Håvard Rue, Lawrence Murray, Henri Pesonen, Martyn Plummer, and Aki\n",
        "Vehtari. 2023. “Past, Present, and Future of Software for Bayesian\n",
        "Inference.”"
      ],
      "id": "16c20a6e-2596-4fca-832d-3dd9d3fea0b9"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}